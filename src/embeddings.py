"""
Embedding modeli yÃ¶netimi.

Bu modÃ¼l metinleri sayÄ±sal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in
sentence-transformers kÃ¼tÃ¼phanesini kullanÄ±r.
"""

from sentence_transformers import SentenceTransformer
import numpy as np
from tqdm import tqdm
import pickle
import os


class EmbeddingModel:
    """TÃ¼rkÃ§e metinler iÃ§in embedding modeli."""

    def __init__(self, model_name="emrecan/bert-base-turkish-cased-mean-nli-stsb-tr"):
        """
        Args:
            model_name: KullanÄ±lacak embedding modeli.
                       TÃ¼rkÃ§e iÃ§in Ã¶zel eÄŸitilmiÅŸ model kullanÄ±yoruz.
        """
        print(f"ğŸ¤– Embedding modeli yÃ¼kleniyor: {model_name}")

        try:
            self.model = SentenceTransformer(model_name)
            self.model_name = model_name
            print("Model baÅŸarÄ±yla yÃ¼klendi!")

            # Model bilgilerini gÃ¶ster
            embedding_dim = self.model.get_sentence_embedding_dimension()
            print(f"Embedding boyutu: {embedding_dim}")

        except Exception as e:
            print(f"Model yÃ¼klenirken hata: {e}")
            raise

    def encode_single(self, text):
        """
        Tek bir metni embedding'e Ã§evirir.

        Args:
            text: Ã‡evrilecek metin

        Returns:
            numpy array: Embedding vektÃ¶rÃ¼
        """
        if not text or not isinstance(text, str):
            return None

        try:
            embedding = self.model.encode(text, convert_to_numpy=True)
            return embedding
        except Exception as e:
            print(f"Encoding hatasÄ±: {e}")
            return None

    def encode_batch(self, texts, batch_size=32, show_progress=True):
        """
        Birden fazla metni toplu olarak embedding'e Ã§evirir.

        Args:
            texts: Metin listesi
            batch_size: AynÄ± anda iÅŸlenecek metin sayÄ±sÄ±
            show_progress: Ä°lerleme Ã§ubuÄŸu gÃ¶ster

        Returns:
            numpy array: Embedding matrisi (n_texts, embedding_dim)
        """
        if not texts:
            return np.array([])

        print(f"{len(texts)} metin embedding'e Ã§evriliyor...")

        try:
            embeddings = self.model.encode(
                texts,
                batch_size=batch_size,
                show_progress_bar=show_progress,
                convert_to_numpy=True
            )

            print(f"Embedding tamamlandÄ±! Shape: {embeddings.shape}")
            return embeddings

        except Exception as e:
            print(f"Batch encoding hatasÄ±: {e}")
            return None

    def encode_documents(self, documents, text_key='text'):
        """
        DokÃ¼man listesini embedding'e Ã§evirir.

        Args:
            documents: DokÃ¼man listesi (dict formatÄ±nda)
            text_key: Metin alanÄ±nÄ±n key'i

        Returns:
            tuple: (embeddings, valid_documents)
        """
        if not documents:
            return None, []

        # Metinleri Ã§Ä±kar
        texts = []
        valid_docs = []

        for doc in documents:
            text = doc.get(text_key, '')
            if text and isinstance(text, str):
                texts.append(text)
                valid_docs.append(doc)

        print(f"{len(valid_docs)} geÃ§erli dokÃ¼man bulundu")

        # Embedding'leri oluÅŸtur
        embeddings = self.encode_batch(texts)

        return embeddings, valid_docs

    def save_embeddings(self, embeddings, documents, filepath):
        """
        Embedding'leri ve dokÃ¼manlarÄ± kaydeder.

        Args:
            embeddings: Embedding matrisi
            documents: DokÃ¼man listesi
            filepath: KayÄ±t yolu
        """
        data = {
            'embeddings': embeddings,
            'documents': documents,
            'model_name': self.model_name
        }

        # KlasÃ¶r yoksa oluÅŸtur
        os.makedirs(os.path.dirname(filepath), exist_ok=True)

        with open(filepath, 'wb') as f:
            pickle.dump(data, f)

        print(f"Embedding'ler kaydedildi: {filepath}")

    @staticmethod
    def load_embeddings(filepath):
        """
        KaydedilmiÅŸ embedding'leri yÃ¼kler.

        Args:
            filepath: Dosya yolu

        Returns:
            dict: {'embeddings', 'documents', 'model_name'}
        """
        if not os.path.exists(filepath):
            print(f"Dosya bulunamadÄ±: {filepath}")
            return None

        with open(filepath, 'rb') as f:
            data = pickle.load(f)

        print(f"Embedding'ler yÃ¼klendi: {filepath}")
        print(f"Embedding shape: {data['embeddings'].shape}")
        print(f"Model: {data['model_name']}")

        return data

    def test_similarity(self, text1, text2):
        """
        Ä°ki metin arasÄ±ndaki benzerliÄŸi test eder.

        Args:
            text1, text2: KarÅŸÄ±laÅŸtÄ±rÄ±lacak metinler

        Returns:
            float: Benzerlik skoru (0-1 arasÄ±)
        """
        emb1 = self.encode_single(text1)
        emb2 = self.encode_single(text2)

        if emb1 is None or emb2 is None:
            return None

        # Cosine benzerliÄŸi hesapla
        similarity = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))

        print(f"\nBenzerlik Testi:")
        print(f"Metin 1: {text1}")
        print(f"Metin 2: {text2}")
        print(f"Benzerlik: {similarity:.4f}")

        return float(similarity)


# Test iÃ§in main fonksiyonu
if __name__ == "__main__":
    # Embedding modelini oluÅŸtur
    embedder = EmbeddingModel()

    # Basit test
    print("\n" + "=" * 60)
    print("BENZERLÄ°K TESTÄ°")
    print("=" * 60)

    # Test metinleri
    embedder.test_similarity(
        "Kitap okumayÄ± seviyorum",
        "Okumak benim hobimdir"
    )

    embedder.test_similarity(
        "Kitap okumayÄ± seviyorum",
        "Futbol oynamak eÄŸlencelidir"
    )

    print("\nâœ¨ Test tamamlandÄ±!")