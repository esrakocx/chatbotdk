"""
Vector Store yÃ¶netimi - FAISS kullanarak.

FAISS (Facebook AI Similarity Search):
VektÃ¶rler arasÄ±nda Ã§ok hÄ±zlÄ± benzerlik aramasÄ± yapan kÃ¼tÃ¼phane.
"""

import faiss
import numpy as np
import pickle
import os
from typing import List, Tuple


class FAISSVectorStore:
    """FAISS tabanlÄ± vektÃ¶r veritabanÄ±."""

    def __init__(self, embedding_dim=768):
        """
        Args:
            embedding_dim: Embedding vektÃ¶rlerinin boyutu
        """
        self.embedding_dim = embedding_dim
        self.index = None
        self.documents = []
        self.is_trained = False

    def create_index(self, embeddings, documents):
        """
        FAISS index'i oluÅŸturur ve embedding'leri ekler.

        Args:
            embeddings: numpy array (n_docs, embedding_dim)
            documents: DokÃ¼man listesi
        """
        print(f"ğŸ”¨ FAISS index oluÅŸturuluyor...")
        print(f"Embedding shape: {embeddings.shape}")

        # Boyut kontrolÃ¼
        if embeddings.shape[1] != self.embedding_dim:
            self.embedding_dim = embeddings.shape[1]
            print(f"âš™ï¸  Embedding boyutu gÃ¼ncellendi: {self.embedding_dim}")

        # L2 (Euclidean) mesafe kullanarak index oluÅŸtur
        # IndexFlatL2: En basit ve en doÄŸru index tipi
        self.index = faiss.IndexFlatL2(self.embedding_dim)

        # Embedding'leri float32'ye Ã§evir (FAISS zorunluluÄŸu)
        embeddings = embeddings.astype('float32')

        # Index'e embedding'leri ekle
        self.index.add(embeddings)
        self.documents = documents
        self.is_trained = True

        print(f"Index oluÅŸturuldu!")
        print(f"Toplam dokÃ¼man sayÄ±sÄ±: {self.index.ntotal}")

    def search(self, query_embedding, top_k=5):
        """
        Sorgu embedding'ine en benzer dokÃ¼manlarÄ± bulur.

        Args:
            query_embedding: Sorgu vektÃ¶rÃ¼
            top_k: KaÃ§ sonuÃ§ dÃ¶ndÃ¼rÃ¼lecek

        Returns:
            list: (skor, dokÃ¼man) tuple'larÄ±nÄ±n listesi
        """
        if not self.is_trained:
            print("Index henÃ¼z oluÅŸturulmamÄ±ÅŸ!")
            return []

        # Query'yi doÄŸru formata Ã§evir
        query_embedding = np.array([query_embedding]).astype('float32')

        # Arama yap
        distances, indices = self.index.search(query_embedding, top_k)

        # SonuÃ§larÄ± hazÄ±rla
        results = []
        for dist, idx in zip(distances[0], indices[0]):
            if idx < len(self.documents):
                # Mesafeyi benzerlik skoruna Ã§evir (dÃ¼ÅŸÃ¼k mesafe = yÃ¼ksek benzerlik)
                similarity = 1 / (1 + dist)
                results.append({
                    'score': float(similarity),
                    'document': self.documents[idx],
                    'distance': float(dist)
                })

        return results

    def save(self, filepath):
        """
        Index ve dokÃ¼manlarÄ± kaydeder.

        Args:
            filepath: KayÄ±t yolu (uzantÄ±sÄ±z)
        """
        if not self.is_trained:
            print("Kaydedilecek bir index yok!")
            return

        # KlasÃ¶r yoksa oluÅŸtur
        os.makedirs(os.path.dirname(filepath) if os.path.dirname(filepath) else '.', exist_ok=True)

        # FAISS index'i kaydet
        index_path = f"{filepath}.index"
        faiss.write_index(self.index, index_path)

        # DokÃ¼manlarÄ± kaydet
        docs_path = f"{filepath}.pkl"
        with open(docs_path, 'wb') as f:
            pickle.dump({
                'documents': self.documents,
                'embedding_dim': self.embedding_dim
            }, f)

        print(f"Vector store kaydedildi:")
        print(f"  - Index: {index_path}")
        print(f"  - DokÃ¼manlar: {docs_path}")

    def load(self, filepath):
        """
        KaydedilmiÅŸ index ve dokÃ¼manlarÄ± yÃ¼kler.

        Args:
            filepath: Dosya yolu (uzantÄ±sÄ±z)
        """
        index_path = f"{filepath}.index"
        docs_path = f"{filepath}.pkl"

        # Dosya kontrolÃ¼
        if not os.path.exists(index_path) or not os.path.exists(docs_path):
            print("Dosyalar bulunamadÄ±!")
            return False

        # Index'i yÃ¼kle
        self.index = faiss.read_index(index_path)

        # DokÃ¼manlarÄ± yÃ¼kle
        with open(docs_path, 'rb') as f:
            data = pickle.load(f)
            self.documents = data['documents']
            self.embedding_dim = data['embedding_dim']

        self.is_trained = True

        print(f"Vector store yÃ¼klendi:")
        print(f"DokÃ¼man sayÄ±sÄ±: {len(self.documents)}")
        print(f"Embedding boyutu: {self.embedding_dim}")

        return True

    def get_stats(self):
        """Index istatistiklerini gÃ¶sterir."""
        if not self.is_trained:
            print("Index henÃ¼z oluÅŸturulmamÄ±ÅŸ!")
            return

        print("\n" + "=" * 60)
        print("VECTOR STORE Ä°STATÄ°STÄ°KLERÄ°")
        print("=" * 60)
        print(f"Toplam dokÃ¼man: {self.index.ntotal}")
        print(f"Embedding boyutu: {self.embedding_dim}")
        print(f"Index tipi: {type(self.index).__name__}")
        print("=" * 60)


# Test iÃ§in main fonksiyonu
if __name__ == "__main__":
    print("Vector Store Test BaÅŸlÄ±yor...\n")

    # Test iÃ§in sahte veri oluÅŸtur
    n_docs = 100
    embedding_dim = 768

    # Rastgele embedding'ler
    test_embeddings = np.random.rand(n_docs, embedding_dim).astype('float32')

    # Test dokÃ¼manlarÄ±
    test_documents = [
        {'text': f'Test dokÃ¼man {i}', 'id': i}
        for i in range(n_docs)
    ]

    # Vector store oluÅŸtur
    store = FAISSVectorStore(embedding_dim=embedding_dim)
    store.create_index(test_embeddings, test_documents)

    # Ä°statistikleri gÃ¶ster
    store.get_stats()

    # Arama testi
    print("\nArama testi yapÄ±lÄ±yor...")
    query = np.random.rand(embedding_dim).astype('float32')
    results = store.search(query, top_k=3)

    print(f"\nEn benzer {len(results)} dokÃ¼man:")
    for i, result in enumerate(results, 1):
        print(f"{i}. Skor: {result['score']:.4f} - {result['document']['text']}")

    # Kaydetme testi
    print("\nKaydetme testi...")
    store.save("./data/test_store")

    # YÃ¼kleme testi
    print("\nYÃ¼kleme testi...")
    new_store = FAISSVectorStore()
    new_store.load("./data/test_store")

    print("\nâœ¨ Test tamamlandÄ±!")